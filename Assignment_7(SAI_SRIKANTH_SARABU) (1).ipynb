{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_7(SAI SRIKANTH SARABU).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6sS8tKPxQFg"
      },
      "source": [
        "##SAI SRIKANTH SARABU\n",
        "##CWID: A20343781"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRQFvRvR_gqP",
        "outputId": "cbb3f00d-7034-4df2-cc10-11cc8d7dd199"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjmU3FCB_sKZ",
        "outputId": "5a650f3d-812d-473f-aa50-412fa7a2c137"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwiPbu9hCPsC"
      },
      "source": [
        "#importing required modules \n",
        "from pyspark import SparkContext, SparkConf\n",
        "import numpy as np\n",
        "import pandas as pd  \n",
        "from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry\n",
        "from pyspark import sql\n",
        "from pyspark.sql import SparkSession,SQLContext"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8cmvAftdU9z"
      },
      "source": [
        "#initializing spark context and spark session\n",
        "sc = SparkContext(\"local\",\"Assignment-3: HITS using Spark\")\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Det7BqCbcI"
      },
      "source": [
        "data = '/content/drive/MyDrive/Sample Data/email-Eu-core.txt' #datapath"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-zcocRVDAP6"
      },
      "source": [
        "dataRDD = sc.textFile(data) #converting data to RDD"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFb1ARSJfAfu"
      },
      "source": [
        "#converting each node to into intergers\n",
        "allEdges = dataRDD.map(lambda x: x.split()).map(lambda x: (int(x[0]),int(x[1])))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-uaDCAhexRR",
        "outputId": "4d811b0b-1649-4023-bb76-8661136605e8"
      },
      "source": [
        "#getting node count\n",
        "nodeCount = allEdges.flatMap(lambda x:x).distinct().count()\n",
        "nodeCount"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1005"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr3KB3Omf8kk"
      },
      "source": [
        "#making all tupples of all the edges with source node, destination node and 1  \n",
        "edgesRDD = allEdges.map(lambda x: (x[0], x[1], 1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2SBoM_ff-qj"
      },
      "source": [
        "#using CoordinateMatrix to get adjacency L of edge direction  \n",
        "L = CoordinateMatrix(edgesRDD,nodeCount,nodeCount).toBlockMatrix()\n",
        "LT = L.transpose()         #taking transpose of the L"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg1eBxTYzeyW"
      },
      "source": [
        "hTupples = []                                             #initialinzing list for initial h value\n",
        "for i in range(nodeCount):                                #looping node count\n",
        "  hTupples.append((i, 0, 1))                              #initializing 1 in h tupple\n",
        "h = CoordinateMatrix(sc.parallelize(hTupples)).toBlockMatrix()        #converting into RDD and initializing h\n",
        "a = None                                                  #initializing a\n",
        "Î» = 1                                                     #initializing Î»\n",
        "Î¼ = 1                                                     #initializing Î¼\n",
        "I = 40\n",
        "for i in range(I):                                        #iterating 40 times\n",
        "  aL = LT.multiply(h)                                     #mutlipling ð¿ð‘‡*â„Ž to compute a\n",
        "  aScalefactor = []                                       #initializing scale factor array for a\n",
        "  aMax = np.max(np.array(aL.toLocalMatrix().toArray()))   #getting max element the aL after converting to array\n",
        "  for i in range(nodeCount):                              \n",
        "    aScalefactor.append((i, i, 1/aMax))                   #appending tupples to construct matrix with only diagonal elements as 1/(max element from a)\n",
        "  a = CoordinateMatrix(sc.parallelize(aScalefactor)).toBlockMatrix().multiply(aL) #scaling each value batween 0 and 1 in RDD by mutlipying scalling factor with aL\n",
        "  hL = L.multiply(a)                                      #mutlipling L*a to compute h\n",
        "  hScalefactor = []                                       #initializing scale factor array for h\n",
        "  hMax = np.max(np.array(hL.toLocalMatrix().toArray()))   #getting max element the hL after converting to array\n",
        "  for j in range(nodeCount):                              \n",
        "    hScalefactor.append((j, j, 1/hMax))                   #appending tupples to construct matrix with only diagonal elements as 1/(max element from h) \n",
        "  h = CoordinateMatrix(sc.parallelize(hScalefactor)).toBlockMatrix().multiply(hL)  #scaling each value batween 0 and 1 in RDD by mutlipying scalling factor with hL"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmQt57fGoMA9",
        "outputId": "dd0c320a-562f-42fe-9573-349cafc2d24f"
      },
      "source": [
        "hArray = np.array(h.toLocalMatrix().toArray())        #converting h to numpy array\n",
        "aArray = np.array(a.toLocalMatrix().toArray())        #converting a to numpy array\n",
        "hSort = np.argsort(hArray, axis = 0)                  #sorting the array using argsort which returns indices of the sorted values \n",
        "hTop5 = hSort[-5:]                                    #getting top 5 hub score\n",
        "hBot5 = hSort[:5]                                     #getting bottom 5 hub score\n",
        "print('Top 5 Hub score ')\n",
        "for i in hTop5:\n",
        "  print('node number -> ',int(i+1),' Hub Score:',float(hArray[i]))        #adding 1 to i to get the node number\n",
        "print('\\nBottom 5 Hub score')\n",
        "for i in hBot5:\n",
        "  print('node number -> ',int(i+1),' Hub Score:',float(hArray[i]))        #Got zeroes due to very less hub score\n",
        "\n",
        "aSort = np.argsort(aArray, axis = 0)\n",
        "aTop5 = aSort[-5:]                                    #getting top 5 authority score\n",
        "aBot5 = aSort[:5]                                     #getting bottom 5 authority score\n",
        "print('\\nTop 5 Authority score ')\n",
        "for i in aTop5:\n",
        "  print('node number -> ',int(i+1),' Authority Score:',float(aArray[i]))\n",
        "print('\\nBottom 5 Authority score')\n",
        "for i in aBot5:\n",
        "  print('node number -> ',int(i+1),' Authority Score:',float(aArray[i]))    #Got zeroes due to very less authority score\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Hub score \n",
            "node number ->  63  Hub Score: 0.7745555183142752\n",
            "node number ->  108  Hub Score: 0.8268162873433461\n",
            "node number ->  122  Hub Score: 0.896653122213392\n",
            "node number ->  83  Hub Score: 0.9047741513157942\n",
            "node number ->  161  Hub Score: 1.0\n",
            "\n",
            "Bottom 5 Hub score\n",
            "node number ->  1005  Hub Score: 0.0\n",
            "node number ->  862  Hub Score: 0.0\n",
            "node number ->  858  Hub Score: 0.0\n",
            "node number ->  657  Hub Score: 0.0\n",
            "node number ->  855  Hub Score: 0.0\n",
            "\n",
            "Top 5 Authority score \n",
            "node number ->  122  Authority Score: 0.8962812611093613\n",
            "node number ->  435  Authority Score: 0.8981523413743511\n",
            "node number ->  63  Authority Score: 0.9273457680741725\n",
            "node number ->  108  Authority Score: 0.9553614962609248\n",
            "node number ->  161  Authority Score: 1.0\n",
            "\n",
            "Bottom 5 Authority score\n",
            "node number ->  902  Authority Score: 0.0\n",
            "node number ->  944  Authority Score: 0.0\n",
            "node number ->  945  Authority Score: 0.0\n",
            "node number ->  525  Authority Score: 0.0\n",
            "node number ->  751  Authority Score: 0.0\n"
          ]
        }
      ]
    }
  ]
}